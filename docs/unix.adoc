= Unix/Linux Commands 
:toc:


[#gnu-parallel]
== GNU Parallel

Split input into parts having no more than 5 lines each, but run j=2 jobs in parallel, and keep input order
```bash
  seq 100 | parallel --keep-order --pipe -N 5 -j 2  'wc -lw && sleep 2 '
  # transform lines in parallel
  seq 100 | parallel --keep-order --pipe -N 5 -j 2  "awk '{print 2 * \$1}' && sleep 2"
```
    
    
Show progress

  seq 100 | parallel --progress --keep-order --pipe -N 5 -j 2  'wc -lw && sleep 2 '


Distribute commands to GPUs, one per device

  echo commands.txt | parallel --progress -j8 CUDA_VISIBLE_DEVICES='$(({%} - 1))' bash -c "{}"
  # eg.
  for i in *.inp; do echo rtg-decode -if $i -o $i.out; done | \
       parallel --progress -j8 CUDA_VISIBLE_DEVICES='$(({%} - 1))' bash -c "{}"


== Parallel Copy

```bash
parallel -j10 --progress cp {} destdir/ ::: srcdir/*
```
Learn more: https://superuser.com/a/536643/266871

== Clear Terminal

We all use `clear` or `CTRL+L` but it's not really a "clear" termianl

    printf "\033c"   #<ESC>c
    reset            # another way
    
Info https://stackoverflow.com/q/5367068/1506477 


[#inverse-select]
== Invert / Exclude files

Info : https://www.tecmint.com/delete-all-files-in-directory-except-one-few-file-extensions/ 

[source,bash]
----
shopt -s extglob  # enable
ls !(conf.yml)    # list all except conf.yml
rm -r !(conf.yml)   # rm all  except conf.yml
rm -v !("filename1"|"filename2")  # multiple exclusions
----

[#bashexit]
== Bash Exit On Error

[source,bash]
----
set -euxo pipefail
----

`-e` exits on error, `-u` errors on undefined variables, `-x` for echoing each statement, and `-o pipefail` exits on command pipe failures.

1. https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/
1. https://stackoverflow.com/a/2871034/1506477 

[#split-assign]
== Split and multiple assignments

Split and assign into varibales
```bash
 IFS="-" read -r a b <<< "xx-yy"
 echo $a $b
```

Split and assign into array 
```bash
IFS="-" read -r -a a <<< "xx-yy"
echo ${a[@]}
```

[#split]
== Split

Merge and distribute one or more .gz files into more evenly sized .gz parts without creating temp files

```bash
# basic
cat *.tsv | split -C 1G -a 5 -d --additional-suffix=.tsv - output-parts/part-
# with gzip
zcat *.gz | split -C 1G -a 5 -d --additional-suffix .tsv --filter='gzip > $FILE.gz' - output-parts/part-
# simpler
zcat *.gz | split -C 1G -a 5 -d --filter='gzip > $FILE.tsv.gz' - output-parts/part-
# with pigz (fast)
pigz -dc *.gz | split -C 1G -a 5 -d --filter='pigz > $FILE.tsv.gz' - output-parts/part-
# "-C 1G" --> "-l 1000000" to have 1M lines per file
```
* `-C 1G` approximatley ~1GB splits by preserving line breaks (i.e., lines are atomic). Note 1GB is intermediate decompressed size. The final part/split files will have lower size after compression.
* `-a 5`  part number has 5 letters/digits i.e., aaaaa-zzzzz or 00000-99999
* `-d` numeric suffixes i.e. 00000-99999 (not aaaaa-zzzzz)
* `--additional-suffix .tsv`  add extra suffix (file extension) to part names
* `--filter='gzip > $FILE'` each part is gzipped (note single quote, $FILE is a placholder). If you dont have .gz in --additional-suffix, then `--filter='gzip > $FILE.gz'`
* `-` (last but one arg) input is from stdin
* `output-parts/part-` output prefix name

